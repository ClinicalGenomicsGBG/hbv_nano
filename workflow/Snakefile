# Run in this env.: /medstore/Development/nanopore_HBV/daniel/micromamba/envs/snakemake_hbv
# Dry run with: snakemake -np
# Run with e.g.: snakemake -c4

#!/usr/bin/env python3


import pandas as pd

global files

configfile: "config/config.yaml"

FILES = glob_wildcards(config["fastq_folder"] + "/{sample}.fastq.gz")    # get all fastq files
NAMES = FILES.sample    # extract sample names

REFERENCE = glob_wildcards("reference_genomes/{ref}.fa")    # get all reference genomes 
REF = REFERENCE.ref    # extract reference genome names

#Only works if minimum_error_rates_2.csv has been created prior to rule all.
#df = pd.read_csv("samtools/minimum_error_rates_2.csv", header=None)
#BAMFILES = df.iloc[:,0].tolist()

#hardcoded (for now)
#BAMFILES = ["bc13.ref_c.bam", "bc14.ref_d.bam", "bc15.ref_d.bam", "bc16.ref_c.bam", "bc17.ref_d.bam", "bc18_neg_ctrl.ref_c.bam"]

rule all:    # specify the final output files
    input:
        expand("fastp/report/{sample}_filt.html", sample=NAMES),   # fastp report
        "samtools/minimum_error_rates.csv",    # minimum error rates [bc**,ref_*,*.****]
        #"samtools/minimum_error_rates_2.csv",   # minimum error rates 2 [bc**-ref_*.bam]
        expand("samtools/{sample}.{ref}.bam", sample=NAMES, ref=REF),    # sorted bam files
        expand("consensus/{sample}.{ref}.fa", sample=NAMES, ref=REF),    # consensus sequences
        expand("consensus/medaka/{sample}.{ref}", sample=NAMES, ref=REF),    # medaka consensus sequences
        expand("consensus/medaka/variants/{sample}.{ref}", sample=NAMES, ref=REF),
        "output/copy_files_done.txt",
        "output/qc.csv"    # read counts


rule fastp:    # filter reads
    input:
        fastq = "data/{sample}.fastq.gz"    # get all fastq files
    output: 
        fastq = "fastp/{sample}_filt.fastq.gz",    # output filtered reads
        report = "fastp/report/{sample}_filt.html"       # output fastp report
    singularity:
        config["fastp"]
    log:
        "logs/fastp/{sample}.log"
    shell:
        "fastp -i {input.fastq} -o {output.fastq} -h {output.report}"


rule minimap2:    # map reads to reference genomes
    input:
        ref = "reference_genomes/{ref}.fa",    # all reference genomes
        fastq = "fastp/{sample}_filt.fastq.gz"    # filtered reads
    output:
        sam = "minimap2/{sample}.{ref}.sam"   # output sam files
    singularity:
        config["minimap2"]
    shell:
        "minimap2 -ax map-ont {input.ref} {input.fastq} > {output.sam}"   # map reads to reference genomes


rule samtools:    # convert sam to bam and sort
    input:
        sam = "minimap2/{sample}.{ref}.sam"    # all sam files
    output:
        bam = "samtools/{sample}.{ref}.bam"    # sorted bam files
    singularity:
        config["samtools"]
    shell:
        "samtools view -bS {input.sam} | samtools sort -o {output.bam}"


rule samtools_stats:    # get error rate for each sample and reference genome
    input:
        bam = "samtools/{sample}.{ref}.bam"    # all bam files
    output:
        stats = "samtools/{sample}.{ref}.txt"  # output the error rate for each sample and reference genome
    singularity:
        config["samtools"]
    shell:
        "samtools stats {input.bam} |grep -i 'error rate' | cut -f 3 > {output.stats}"    # extract error rates from samtools stats output and write to txt files


rule collate_error_rates:    # collate error rates from all samples and reference genomes
    input:
        expand('samtools/{sample}.{ref}.txt', sample=NAMES, ref=REF)
    output:
        "samtools/error_rates.csv"    # all error rates
    run:
        with open(output[0], 'w') as out:
            for path in input:
                sample = path.split('.')[0].split('/')[1]
                ref = path.split('.')[1]

                for error in open(path):
                    out.write(f"{sample},{ref},{error}")    # write error rates to csv file [sample, reference genome, error rate]


rule minimum_error_rates:    # get minimum error rate for each sample
    input:
        "samtools/error_rates.csv"
    output:
        "samtools/minimum_error_rates.csv",
        "samtools/minimum_error_rates_2.csv"
    script:
        "scripts/error_rate.py"                                                                                              


rule consensus:    # generate consensus sequences
    input:
        bam = "samtools/{sample}.{ref}.bam"
    output:
        fasta = "consensus/{sample}.{ref}.fa"
    singularity:
        config["samtools"]
    shell:
        "samtools consensus -m simple -d20 {input.bam} > {output.fasta}"


rule medaka:
    input:
        fastq = "fastp/{sample}_filt.fastq.gz",
        fasta = "consensus/{sample}.{ref}.fa"
    params:
        model = "r1041_e82_400bps_sup_g615"
    output:
        fasta_medaka = directory("consensus/medaka/{sample}.{ref}")
    singularity:
        config["medaka"]
    shell:
        "medaka_consensus -r N -i {input.fastq} -d {input.fasta} -o {output.fasta_medaka} -m {params.model}"

rule medaka_variant:
    input:
        fastq = "fastp/{sample}_filt.fastq.gz",
        fasta = "consensus/medaka/{sample}.{ref}/consensus.fasta"
    output:
        vcf = directory("consensus/medaka/variants/{sample}.{ref}")
    singularity:
        "images/medaka_1.11.3.img"
    shell:
        "medaka_haploid_variant -i {input.fastq} -r {input.fasta} -o {output.vcf} -m r1041_e82_400bps_sup_g615"

rule copy_files:
    input:
        "samtools/minimum_error_rates.csv",
        expand("consensus/medaka/{sample}.{ref}", sample=NAMES, ref=REF)
    output:
        "output/copy_files_done.txt"
    script:
        "scripts/copy_files.py"

rule qc:
    input:
        "output/copy_files_done.txt",
        #expand("output/{sample}.{ref}_medaka.fa", sample=NAMES, ref=REF)
    output:
        "output/qc.csv"
    script:
        "scripts/qc.py"